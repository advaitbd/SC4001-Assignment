{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp6KAX1UXqaK"
   },
   "source": [
    "CS4001/4042 Assignment 1, Part B, Q4\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WsfKoCAMj9uo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjdf67uIarDX"
   },
   "source": [
    "Your co-investigators used a linear regression model to rapidly test out several combinations of train/test splits and shared with you their findings in a brief report attached in Appendix A below. You wish to investigate whether your deep learning model corroborates with their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M3-BW2LW4Icq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alibi-detect\n",
      "  Downloading alibi_detect-0.11.4-py3-none-any.whl (372 kB)\n",
      "\u001b[K     |████████████████████████████████| 372 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numba!=0.54.0,<0.58.0,>=0.50.0\n",
      "  Downloading numba-0.57.1-cp39-cp39-macosx_10_9_x86_64.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 21.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib<4.0.0,>=3.0.0 in ./env/lib/python3.9/site-packages (from alibi-detect) (3.8.0)\n",
      "Collecting Pillow<10.0.0,>=5.4.1\n",
      "  Downloading Pillow-9.5.0-cp39-cp39-macosx_10_10_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 29.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python<5.0.0,>=3.2.0\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-macosx_10_16_x86_64.whl (54.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 54.7 MB 555 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.0.0\n",
      "  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.7 MB 19.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.21.0 in ./env/lib/python3.9/site-packages (from alibi-detect) (2.31.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in ./env/lib/python3.9/site-packages (from alibi-detect) (2.1.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in ./env/lib/python3.9/site-packages (from alibi-detect) (1.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in ./env/lib/python3.9/site-packages (from alibi-detect) (4.66.1)\n",
      "Collecting dill<0.4.0,>=0.3.0\n",
      "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<2.0.0,>=1.8.0\n",
      "  Downloading pydantic-1.10.13-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 18.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.3.0 in ./env/lib/python3.9/site-packages (from alibi-detect) (1.11.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.9/site-packages (from alibi-detect) (4.8.0)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in ./env/lib/python3.9/site-packages (from alibi-detect) (2.0.10)\n",
      "Collecting scikit-image!=0.17.1,<0.22,>=0.14.2\n",
      "  Downloading scikit_image-0.21.0-cp39-cp39-macosx_10_9_x86_64.whl (13.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.0 MB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toml<1.0.0,>=0.10.1\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in ./env/lib/python3.9/site-packages (from alibi-detect) (1.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.12.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.1.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env/lib/python3.9/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.43.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./env/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.17.0)\n",
      "Collecting llvmlite<0.41,>=0.40.0dev0\n",
      "  Downloading llvmlite-0.40.1-cp39-cp39-macosx_10_9_x86_64.whl (30.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.4 MB 136 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy<2.0.0,>=1.16.2\n",
      "  Downloading numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.8 MB 143 kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in ./env/lib/python3.9/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./env/lib/python3.9/site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.9/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.9/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.9/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.9/site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2023.7.22)\n",
      "Collecting lazy_loader>=0.2\n",
      "  Using cached lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.9.26-py3-none-any.whl (222 kB)\n",
      "\u001b[K     |████████████████████████████████| 222 kB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.8 in ./env/lib/python3.9/site-packages (from scikit-image!=0.17.1,<0.22,>=0.14.2->alibi-detect) (3.1)\n",
      "Collecting imageio>=2.27\n",
      "  Downloading imageio-2.31.5-py3-none-any.whl (313 kB)\n",
      "\u001b[K     |████████████████████████████████| 313 kB 30.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Using cached PyWavelets-1.4.1-cp39-cp39-macosx_10_13_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./env/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env/lib/python3.9/site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.2.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-macosx_10_7_x86_64.whl (439 kB)\n",
      "\u001b[K     |████████████████████████████████| 439 kB 47.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 18.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in ./env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.12.4)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.10.3-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[K     |████████████████████████████████| 296 kB 52.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp39-cp39-macosx_10_7_x86_64.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 22.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.9/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.1)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers<5.0.0,>=4.0.0->alibi-detect) (2023.9.2)\n",
      "Installing collected packages: Pillow, numpy, huggingface-hub, tokenizers, tifffile, safetensors, regex, PyWavelets, llvmlite, lazy-loader, imageio, transformers, toml, scikit-image, pydantic, opencv-python, numba, dill, alibi-detect\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 10.0.1\n",
      "    Uninstalling Pillow-10.0.1:\n",
      "      Successfully uninstalled Pillow-10.0.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.0\n",
      "    Uninstalling numpy-1.26.0:\n",
      "      Successfully uninstalled numpy-1.26.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.4.2\n",
      "    Uninstalling pydantic-2.4.2:\n",
      "      Successfully uninstalled pydantic-2.4.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytorch-tabnet 4.0 requires torch<2.0,>=1.2, but you have torch 2.1.0 which is incompatible.\u001b[0m\n",
      "Successfully installed Pillow-9.5.0 PyWavelets-1.4.1 alibi-detect-0.11.4 dill-0.3.7 huggingface-hub-0.17.3 imageio-2.31.5 lazy-loader-0.3 llvmlite-0.40.1 numba-0.57.1 numpy-1.24.4 opencv-python-4.8.1.78 pydantic-1.10.13 regex-2023.10.3 safetensors-0.4.0 scikit-image-0.21.0 tifffile-2023.9.26 tokenizers-0.14.1 toml-0.10.2 transformers-4.34.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E7dD3Ihi4GF9"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_tabular\n",
    "import math\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xJjXNMOqcHVJ"
   },
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fOUcXL5OXASY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 15:02:52,166 - {pytorch_tabular.tabular_model:129} - INFO - Experiment Tracking is turned off\n",
      "2023-10-10 15:02:52,168 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59ceb33237a42b88c0e1623391cfc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.4388472512009519\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "# TODO: Enter your code here\n",
    "# model is in saved_models/b1.ckpt\n",
    "\n",
    "model = pytorch_tabular.tabular_model.TabularModel.load_model('saved_models/b1')\n",
    "\n",
    "test_data = df[df['year'] == 2022]\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "# print(\"RMSE: \", math.sqrt(mean_squared_error(test_data['resale_price'], predictions['resale_price_prediction'])))\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsbs0iMiaUy-"
   },
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B4FLRQfBaRS-"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da2cb6c78a24be0be1b8f05ff8eb6e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.16212590443081432\n"
     ]
    }
   ],
   "source": [
    "# TODO: Enter your code here\n",
    "\n",
    "test_data = df[df['year'] == 2023]\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "11mU8sxcaSAP"
   },
   "source": [
    "> Did model degradation occur for the deep learning model?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nviGacm6aSlf"
   },
   "source": [
    "As observed from the decrease in R2. We can observe that model degradatoin has occurred for this model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KyiP8gBAcABD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ruldtSTDcYzt"
   },
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2019 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "nGbdZc3ocYbB"
   },
   "outputs": [],
   "source": [
    "target = ['resale_price']\n",
    "categorical_cols = ['month', 'town', 'flat_model_type', 'storey_range']\n",
    "continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm']\n",
    "\n",
    "# Extract unique categories for each categorical column\n",
    "category_map = {}\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    category_map[i] = df[col].unique().tolist()\n",
    "\n",
    "n_ref = 1000\n",
    "n_test = 1000\n",
    "\n",
    "# Splitting the dataset into train (reference) and test based on the 'year' column\n",
    "X_train = df[df['year'] <= 2019]\n",
    "X_test = df[df['year'] == 2023]\n",
    "\n",
    "# Limiting the number of rows for both reference and test datasets\n",
    "X_train = X_train[:n_ref]\n",
    "X_test = X_test[:n_test]\n",
    "\n",
    "X_ref = X_train[categorical_cols + continuous_cols].values\n",
    "X_test = X_test[categorical_cols + continuous_cols].values\n",
    "\n",
    "y_ref = X_train[target].values\n",
    "y_test = df[df['year'] == 2023][target].values[:n_test]\n",
    "\n",
    "categories_per_feature = {f: None for f in list(category_map.keys())}\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? Yes\n",
      "month -- Drift? No -- Chi2 0.000 -- p-value 1.000\n",
      "town -- Drift? Yes -- Chi2 667.474 -- p-value 0.000\n",
      "flat_model_type -- Drift? Yes -- Chi2 77.586 -- p-value 0.000\n",
      "storey_range -- Drift? Yes -- Chi2 38.800 -- p-value 0.001\n",
      "dist_to_nearest_stn -- Drift? No -- K-S 0.055 -- p-value 0.094\n",
      "dist_to_dhoby -- Drift? Yes -- K-S 0.218 -- p-value 0.000\n",
      "degree_centrality -- Drift? No -- K-S 0.029 -- p-value 0.783\n",
      "eigenvector_centrality -- Drift? Yes -- K-S 0.195 -- p-value 0.000\n",
      "remaining_lease_years -- Drift? Yes -- K-S 0.271 -- p-value 0.000\n",
      "floor_area_sqm -- Drift? Yes -- K-S 0.134 -- p-value 0.000\n"
     ]
    }
   ],
   "source": [
    "predictions = cd.predict(X_test)\n",
    "labels = ['No','Yes']\n",
    "print('Drift? {}'.format(labels[predictions['data']['is_drift']]))\n",
    "\n",
    "fpreds = cd.predict(X_test, drift_type='feature')\n",
    "\n",
    "for f in range(cd.n_features):\n",
    "    stat = 'Chi2' if f in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = feature_names[f]\n",
    "    is_drift = fpreds['data']['is_drift'][f]\n",
    "    stat_val, p_val = fpreds['data']['distance'][f], fpreds['data']['p_val'][f]\n",
    "    print(f'{fname} -- Drift? {labels[is_drift]} -- {stat} {stat_val:.3f} -- p-value {p_val:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmj3qq3PkJUf"
   },
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5UOsX4JqkZ9S"
   },
   "source": [
    "Concept Drift. This is because if the measures change the relationship between all the features and the resale_price, this would impact the conditions by which X impacts Y, thereby changing P(Y|X). This represents Concept Drift."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DM2OoOJdkZj1"
   },
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "V3licBjskdLL"
   },
   "source": [
    "- town\n",
    "- flat_model_type\n",
    "- storey_range\n",
    "- dist_to_dhoby\n",
    "- eigenvector_centrality\n",
    "- remaining_lease_years\n",
    "- floor_area_sqm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yB3fSvKskhEJ"
   },
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "9UpP7K6Tkglx"
   },
   "source": [
    "The model used was trained on data from 2019 and before. Hence one way to address the model degradation is to train it on updated data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "EqFinZObcYXu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "2023-10-10 16:23:16,870 - {pytorch_tabular.tabular_model:473} - INFO - Preparing the DataLoaders\n",
      "2023-10-10 16:23:16,881 - {pytorch_tabular.tabular_datamodule:290} - INFO - Setting up the datamodule for regression task\n",
      "2023-10-10 16:23:17,039 - {pytorch_tabular.tabular_model:521} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "2023-10-10 16:23:17,070 - {pytorch_tabular.tabular_model:268} - INFO - Preparing the Trainer\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:589: LightningDeprecationWarning: The Trainer argument `auto_select_gpus` has been deprecated in v1.9.0 and will be removed in v2.0.0. Please use the function `pytorch_lightning.accelerators.find_usable_cuda_devices` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-10-10 16:23:17,159 - {pytorch_tabular.tabular_model:573} - INFO - Auto LR Find Started\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory /Users/advait/Desktop/gitpositories/SC4001-Assignment/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('valid_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('valid_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1acfa0fd174b52a1cd2c8a376e4a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/core/module.py:493: UserWarning: You called `self.log('train_mean_squared_error', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at /Users/advait/Desktop/gitpositories/SC4001-Assignment/.lr_find_39a96633-fd70-4b0a-8742-aabf70fbc156.ckpt\n",
      "Restored all states from the checkpoint file at /Users/advait/Desktop/gitpositories/SC4001-Assignment/.lr_find_39a96633-fd70-4b0a-8742-aabf70fbc156.ckpt\n",
      "2023-10-10 16:23:21,788 - {pytorch_tabular.tabular_model:575} - INFO - Suggested LR: 0.5754399373371567. For plot and detailed analysis, use `find_learning_rate` method.\n",
      "2023-10-10 16:23:21,788 - {pytorch_tabular.tabular_model:582} - INFO - Training Started\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53ffdbee1a43eba4e34f5a06a12fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 16:25:38,355 - {pytorch_tabular.tabular_model:584} - INFO - Training the model completed\n",
      "2023-10-10 16:25:38,359 - {pytorch_tabular.tabular_model:1258} - INFO - Loading the best model\n",
      "/Users/advait/Desktop/gitpositories/SC4001-Assignment/env/lib/python3.9/site-packages/pytorch_lightning/utilities/cloud_io.py:33: LightningDeprecationWarning: `pytorch_lightning.utilities.cloud_io.get_filesystem` has been deprecated in v1.8.0 and will be removed in v2.0.0. Please use `lightning_fabric.utilities.cloud_io.get_filesystem` instead.\n",
      "  rank_zero_deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x7f9649b84b20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train=df[df['year'] <= 2022])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46b9ffaf8c3441694962944dda0e432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.5254131746577532\n"
     ]
    }
   ],
   "source": [
    "test_data = df[df['year'] == 2023]\n",
    "\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "print(\"R2: \", r2_score(test_data['resale_price'], predictions['resale_price_prediction']))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wQG9hZvAaq5g"
   },
   "source": [
    "### Appendix A\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ARi2OxbDuZ"
   },
   "source": [
    "Here are our results from a linear regression model. We used StandardScaler for continuous variables and OneHotEncoder for categorical variables.\n",
    "\n",
    "While 2021 data can be predicted well, test R2 dropped rapidly for 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| Year <= 2020 | 2021     | 0.76    |\n",
    "| Year <= 2020 | **2022**     | 0.41    |\n",
    "| Year <= 2020 | **2023**     | **0.10**   |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vmv91FqgbI8h"
   },
   "source": [
    "Similarly, a model trained on 2017 data can predict 2018-2021 well (with slight degradation in performance for 2021), but drops drastically in 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2017         | 2018     | 0.90    |\n",
    "|              | 2019     | 0.89    |\n",
    "|              | 2020     | 0.87    |\n",
    "|              | 2021     | 0.72    |\n",
    "|              | **2022**     | **0.37**    |\n",
    "|              | **2023**     | **0.09**    |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ayKGs106bI6S"
   },
   "source": [
    "With the test set fixed at year 2021, training on data from 2017-2020 still works well on the test data, with minimal degradation. Training sets closer to year 2021 generally do better.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2020         | 2021     | 0.81    |\n",
    "| 2019         | 2021     | 0.75    |\n",
    "| 2018         | 2021     | 0.73    |\n",
    "| 2017         | 2021     | 0.72    |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWUKTcEICJ0j/YcXkGkr53",
   "collapsed_sections": [
    "wQG9hZvAaq5g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
